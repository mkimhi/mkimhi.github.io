---
title: "Increase the latency of LLM"
excerpt: "By adverserial attack"
collection: projects
---


The idea is to increase the latency, and by that the power consumption-> cost of inference LLM.

mechanisms like [Early Exit](https://arxiv.org/pdf/2312.04916) and [Speculative Decoding](https://pytorch.org/blog/hitchhikers-guide-speculative-decoding/) can be attacked via simple adverserial attacks.


<br/><img src='/images/bert.png',width="600"/><br/>
image from https://arxiv.org/abs/2006.04152
